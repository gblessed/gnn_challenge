{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g2F4VUMlkju",
        "outputId": "8657e724-0101-4e1d-f409-9bf65a2ab117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Fall23/Capstone Research/new_efforts\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Fall23/Capstone Research/new_efforts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMbQkotnWfTf",
        "outputId": "907bd800-2c6b-4a39-92d7-570a9f73637d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "from torchmetrics.regression import MeanAbsolutePercentageError\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "WHCFjMAb7Uep"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_path = \"/content/drive/MyDrive/Fall23/Capstone Research/new_efforts/extracted_15_10_cv/0\"\n",
        "ds_val = \"/content/drive/MyDrive/Fall23/Capstone Research/new_efforts/extracted_15_10_cv/0\"\n",
        "ds_train = tf.data.Dataset.load(f\"{ds_path}/training\", compression=\"GZIP\")\n",
        "ds_val = tf.data.Dataset.load(f\"{ds_path}/validation\", compression=\"GZIP\")\n"
      ],
      "metadata": {
        "id": "FHYHsMy0F-tl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as  np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "# Convert TF dataset to PyTorch dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tf_dataset):\n",
        "        self.tf_dataset = tf_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        # Calculate the length of the dataset\n",
        "        # Implement according to the structure of your dataset\n",
        "        return len(self.tf_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve an item from the dataset\n",
        "        # Implement according to the structure of your dataset\n",
        "        return self.tf_dataset[idx]"
      ],
      "metadata": {
        "id": "MSJSGWMMSHj4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = []\n",
        "# X_graphs = []\n",
        "for item in ds_train:\n",
        "    # Assuming the elements in the dataset are tensors, convert them into a format compatible with PyTorch\n",
        "    train_list.append((item[0], item[1].numpy()))\n",
        "\n",
        "val_list = []\n",
        "# X_graphs = []\n",
        "for item in ds_val:\n",
        "    # Assuming the elements in the dataset are tensors, convert them into a format compatible with PyTorch\n",
        "    val_list.append((item[0], item[1].numpy()))\n"
      ],
      "metadata": {
        "id": "57d9BPpH3H8Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scores_fields = {\n",
        "    \"flow_traffic\",\n",
        "    \"flow_packets\",\n",
        "    \"flow_packet_size\",\n",
        "    \"link_capacity\",\n",
        "}"
      ],
      "metadata": {
        "id": "XwiMhCnkDi2h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_max_scores_fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kB6cke0BfPZ",
        "outputId": "1c40e697-7e42-4c58-c44a-0bdc896195f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flow_packet_size', 'flow_packets', 'flow_traffic', 'link_capacity'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_min_max_dict(\n",
        "    ds: tf.data.Dataset, params, include_y = None\n",
        "):\n",
        "    \"\"\"Get the min and the max-min for different parameters of a dataset. Later used by the models for the min-max normalization.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ds : tf.data.Dataset\n",
        "        Training dataset where to base the min-max normalization from.\n",
        "\n",
        "    params : List[str]\n",
        "        List of strings indicating the parameters to extract the features from.\n",
        "\n",
        "    include_y : Optional[str], optional\n",
        "        Indicates if to also extract the features of the output variable.\n",
        "        Inputs indicate the string key used on the return dict. If None, it is not included.\n",
        "        By default None.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict[str, Tuple[np.ndarray, np.ndarray]]\n",
        "        Dictionary containing the values needed for the min-max normalization.\n",
        "        The first value is the min value of the parameter, and the second is 1 / (max - min).\n",
        "    \"\"\"\n",
        "\n",
        "    # Use first sample to get the shape of the tensors\n",
        "    iter_ds = iter(ds)\n",
        "    sample, label = next(iter_ds)\n",
        "    params_lists = {param: sample[param].numpy() for param in params}\n",
        "    if include_y:\n",
        "        params_lists[include_y] = label.numpy()\n",
        "\n",
        "    # Include the rest of the samples\n",
        "    for sample, label in iter_ds:\n",
        "        for param in params:\n",
        "            params_lists[param] = np.concatenate(\n",
        "                (params_lists[param], sample[param].numpy()), axis=0\n",
        "            )\n",
        "        if include_y:\n",
        "            params_lists[include_y] = np.concatenate(\n",
        "                (params_lists[include_y], label.numpy()), axis=0\n",
        "            )\n",
        "\n",
        "    scores = dict()\n",
        "    for param, param_list in params_lists.items():\n",
        "        min_val = np.min(param_list, axis=0)\n",
        "        min_max_val = np.max(param_list, axis=0) - min_val\n",
        "        if min_max_val.size == 1 and min_max_val == 0:\n",
        "            scores[param] = [min_val, 0]\n",
        "            print(f\"Min-max normalization Warning: {param} has a max-min of 0.\")\n",
        "        elif min_max_val.size > 1 and np.any(min_max_val == 0):\n",
        "            min_max_val[min_max_val != 0] = 1 / min_max_val[min_max_val != 0]\n",
        "            scores[param] = [min_val, min_max_val]\n",
        "            print(\n",
        "                f\"Min-max normalization Warning: Several values of {param} has a max-min of 0.\"\n",
        "            )\n",
        "        else:\n",
        "            scores[param] = [min_val, 1 / min_max_val]  ## return min and 1/max-min\n",
        "\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "kuJTj7zVAvnM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(train_list)\n",
        "train_dataset = CustomDataset(train_list)\n",
        "val_dataset = CustomDataset(val_list)\n"
      ],
      "metadata": {
        "id": "vwhr0VOooRx0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizers = get_min_max_dict(ds_train, min_max_scores_fields)"
      ],
      "metadata": {
        "id": "Oai6VDq09VLQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer"
      ],
      "metadata": {
        "id": "7JkmZn93XNzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class PathEmbedding(nn.Module):\n",
        "    def __init__(self, path_state_dim):\n",
        "        super(PathEmbedding, self).__init__()\n",
        "        self.path_state_dim = path_state_dim\n",
        "        self.flow_embedding = nn.Sequential(\n",
        "            nn.Linear(7, self.path_state_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.path_state_dim, self.path_state_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.flow_embedding(x)\n",
        "\n",
        "class LinkEmbedding(nn.Module):\n",
        "    def __init__(self, link_state_dim):\n",
        "        super(LinkEmbedding, self).__init__()\n",
        "        self.link_state_dim = link_state_dim\n",
        "        self.link_embedding = nn.Sequential(\n",
        "            nn.Linear(2, self.link_state_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.link_state_dim, self.link_state_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.link_embedding(x)\n",
        "\n",
        "class PathReadout(nn.Module):\n",
        "    def __init__(self, path_state_dim, link_state_dim):\n",
        "        super(PathReadout, self).__init__()\n",
        "        self.path_state_dim = path_state_dim\n",
        "        self.link_state_dim = link_state_dim\n",
        "        self.readout_path = nn.Sequential(\n",
        "            nn.Linear(self.path_state_dim, self.link_state_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.link_state_dim // 2, self.link_state_dim // 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.link_state_dim // 4, 1),\n",
        "            nn.Softplus()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.readout_path(x)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tqt-p75a4lVP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyCombinedModel(nn.Module):\n",
        "    def __init__(self, link_state_dim, path_state_dim, num_layers=2):\n",
        "        super(MyCombinedModel, self).__init__()\n",
        "        self.link_embed = LinkEmbedding(link_state_dim)  # Assuming LinkEmbedding is defined\n",
        "        self.flow_embedded = PathEmbedding(path_state_dim)  # Assuming PathEmbedding is defined\n",
        "        self.reader = PathReadout(path_state_dim, link_state_dim)  # Assuming PathReadout is defined\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=link_state_dim, dim_feedforward=64, batch_first=True, nhead=2)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.link_update = nn.GRUCell(\n",
        "          link_state_dim, link_state_dim\n",
        "        )\n",
        "\n",
        "        self.path_update = nn.GRUCell(\n",
        "          path_state_dim, path_state_dim\n",
        "        )\n",
        "    def forward(self, link_to_path, path_to_link,  link_capacity,  all_flows_used, flow_traffic, link_capacity_orig):\n",
        "\n",
        "        path_state = self.flow_embedded(all_flows_used)\n",
        "\n",
        "\n",
        "        ##########################\n",
        "          ## link to path     ##\n",
        "        #########################\n",
        "\n",
        "\n",
        "        all_link_capacities_used = []\n",
        "        loads = []\n",
        "\n",
        "        for i in range(len(path_to_link)):\n",
        "\n",
        "            loads.append(torch.sum(torch.index_select(torch.tensor(flow_traffic), 0, torch.tensor(path_to_link[i][:, 0 ]).type(torch.int64)))/  (link_capacity_orig[i] * 1e9))\n",
        "\n",
        "\n",
        "        loads_capacities = torch.cat((torch.tensor(loads).unsqueeze(1), torch.tensor(link_capacity)), dim=1)\n",
        "\n",
        "\n",
        "        ## initialize the hidden state for links\n",
        "        link_state = self.link_embed(loads_capacities)\n",
        "\n",
        "\n",
        "\n",
        "        for _ in range(4):\n",
        "\n",
        "          ##########################\n",
        "            ## link to path     ##\n",
        "          #########################\n",
        "          link_gather  = []\n",
        "          for link_to_pat in link_to_path:\n",
        "              link_gather.append(link_state[link_to_pat])\n",
        "          prev_path_state = path_state\n",
        "\n",
        "          hx = prev_path_state\n",
        "\n",
        "          path_state = []\n",
        "          path_state_sequence = []\n",
        "          for i, link_stated in enumerate(link_gather):\n",
        "\n",
        "            hx_i = self.path_update(link_stated, torch.tile(hx[i].unsqueeze(0), (len(link_stated),1)))\n",
        "            path_state_sequence.append(torch.cat( (prev_path_state[i].unsqueeze(0),  hx_i), dim = 0  ))\n",
        "\n",
        "            path_state.append(hx_i[-1, :])\n",
        "\n",
        "          path_state = torch.stack(path_state)\n",
        "\n",
        "\n",
        "\n",
        "          ##########################\n",
        "            ## path to link     ##\n",
        "          #########################\n",
        "\n",
        "          path_sum = []\n",
        "\n",
        "          padded_tensor =  torch.nn.utils.rnn.pad_sequence(path_state_sequence, batch_first=True, padding_value=0)\n",
        "\n",
        "\n",
        "\n",
        "          for path_to_lin in path_to_link:\n",
        "              path_sum.append(torch.sum(padded_tensor[path_to_lin[:,0], path_to_lin[:,1]], dim=0) )\n",
        "\n",
        "          path_sum = torch.stack(path_sum)\n",
        "          link_state = self.link_update(path_sum, link_state)\n",
        "\n",
        "\n",
        "        capacity_gather = []\n",
        "        for i, values in enumerate(link_to_path):\n",
        "          capacity_gather.append(link_capacity_orig[values])\n",
        "\n",
        "        delays = []\n",
        "\n",
        "        for i, path_state_seq in enumerate(path_state_sequence):\n",
        "            occupancy = self.reader(path_state_seq[1:, :])\n",
        "            delays.append(torch.sum(occupancy[:len(capacity_gather[i])]/torch.tensor(capacity_gather[i]).T[0]).unsqueeze(0))\n",
        "\n",
        "\n",
        "        return torch.cat(delays)\n",
        "\n",
        "link_state_dim = 64\n",
        "path_state_dim = 64\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "num_layers = 2  # Example value for the number of layers\n",
        "\n",
        "model = MyCombinedModel(link_state_dim,  path_state_dim, num_layers)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "# optimizer =  torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, patience=10, mode= 'min')\n",
        "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00001, max_lr=0.1)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = MeanAbsolutePercentageError()\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "  fake_batch_size= 8\n",
        "  with tqdm(train_dataset, total=len(train_dataset)) as pbar:\n",
        "    predictions = []\n",
        "    y_all = []\n",
        "    loss = 0\n",
        "    loss = torch.tensor([0.0])\n",
        "\n",
        "    for i,batch in enumerate(pbar):\n",
        "        # print(batch)\n",
        "        # Process the batch as needed\n",
        "        data, labels = batch  # Modify this according to the structure of your data\n",
        "        # print(data.keys())\n",
        "        link_capacity_orig = data['link_capacity'].numpy()\n",
        "        flow_traffic = (data['flow_traffic'].numpy() - normalizers[\"flow_traffic\"][0]) *normalizers[\"flow_traffic\"][1]\n",
        "        flow_packets = (data['flow_packets'].numpy() - normalizers[\"flow_packets\"][0]) *normalizers[\"flow_packets\"][1]\n",
        "        link_capacity = (data['link_capacity'].numpy()  - normalizers[\"link_capacity\"][0]) *normalizers[\"link_capacity\"][1]\n",
        "        flow_packet_size = (data['flow_packet_size'].numpy() - normalizers[\"flow_packet_size\"][0])  * normalizers[\"link_capacity\"][1]\n",
        "        flow_type = data['flow_type'].numpy()\n",
        "        flow_length = data['flow_length'].numpy()\n",
        "        link_to_path = data['link_to_path'].numpy()\n",
        "        flow_ipg_mean = data['flow_ipg_mean'].numpy()\n",
        "        flow_ipg_var = data['flow_ipg_var'].numpy()\n",
        "        path_to_link = data['path_to_link'].numpy()\n",
        "        y_vals = torch.tensor(labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        all_flows_used = torch.tensor(np.concatenate([flow_traffic,flow_packets, flow_type, flow_type, np.expand_dims(flow_length,axis=1)], axis=1,dtype=np.float32 ) )\n",
        "\n",
        "        outputs = model(link_to_path, path_to_link, link_capacity,all_flows_used, flow_traffic, link_capacity_orig)\n",
        "\n",
        "        predictions.extend(outputs.detach().numpy())\n",
        "        loss += criterion(outputs, y_vals ) # Compute the loss.\n",
        "        if i%fake_batch_size == 0 or i== len(train_dataset):\n",
        "          loss = loss/fake_batch_size\n",
        "          loss.backward()  # Derive gradients.\n",
        "          optimizer.step()  # Update parameters based on gradients.\n",
        "          optimizer.zero_grad()  # Clear gradients.\n",
        "          loss = torch.tensor([0.0])\n",
        "\n",
        "        pbar.set_description(f\"Loss: {loss.item()/fake_batch_size:.4f}\")\n",
        "        y_all.extend(labels)\n",
        "    print(\"train loss = \",criterion(torch.tensor(predictions), torch.tensor(y_all )).item())\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with tqdm(val_dataset, total=len(val_dataset)) as pbar:\n",
        "      predictions = []\n",
        "      y_all = []\n",
        "      for batch in  pbar:\n",
        "          # print(batch)\n",
        "          # Process the batch as needed\n",
        "          data, labels = batch  # Modify this according to the structure of your data\n",
        "          # print(data.keys())\n",
        "          link_capacity_orig = data['link_capacity'].numpy()\n",
        "          flow_traffic = (data['flow_traffic'].numpy() - normalizers[\"flow_traffic\"][0]) *normalizers[\"flow_traffic\"][1]\n",
        "          flow_packets = (data['flow_packets'].numpy() - normalizers[\"flow_packets\"][0]) *normalizers[\"flow_packets\"][1]\n",
        "          link_capacity = (data['link_capacity'].numpy()  - normalizers[\"link_capacity\"][0]) *normalizers[\"link_capacity\"][1]\n",
        "          flow_packet_size = (data['flow_packet_size'].numpy() - normalizers[\"flow_packet_size\"][0])  * normalizers[\"link_capacity\"][1]\n",
        "          flow_type = data['flow_type'].numpy()\n",
        "          flow_length = data['flow_length'].numpy()\n",
        "          link_to_path = data['link_to_path'].numpy()\n",
        "          flow_ipg_mean = data['flow_ipg_mean'].numpy()\n",
        "          flow_ipg_var = data['flow_ipg_var'].numpy()\n",
        "          path_to_link = data['path_to_link'].numpy()\n",
        "          # y_vals = torch.tensor(labels)\n",
        "\n",
        "          # path_gather_traffic = 0\n",
        "          # load = torch.sum(path_gather_traffic, dim=1) / (link_capacity * 1e9)\n",
        "          all_flows_used = torch.tensor(np.concatenate([flow_traffic,flow_packets, flow_type, flow_type, np.expand_dims(flow_length,axis=1)], axis=1,dtype=np.float32 ) )\n",
        "\n",
        "          outputs = model(link_to_path, path_to_link, link_capacity,all_flows_used, flow_traffic, link_capacity_orig)\n",
        "          predictions.extend(outputs.detach().numpy())\n",
        "          y_all.extend(labels)\n",
        "\n",
        "          # scheduler.step(criterion(torch.tensor(predictions), torch.tensor(y_all )))\n",
        "    print(\"val loss = \",criterion(torch.tensor(predictions), torch.tensor(y_all )).item())\n"
      ],
      "metadata": {
        "id": "DCKPbKLyPQmP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 150):\n",
        "    print(\"epoch \", epoch)\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuv0R7wLICLK",
        "outputId": "fd0aa8d9-821b-42cf-f56d-f9c8033a5242"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 0.3750: 100%|██████████| 3380/3380 [20:02<00:00,  2.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss =  1.8529808521270752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:15<00:00,  6.24it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss =  1.0\n",
            "epoch  2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 0.3750: 100%|██████████| 3380/3380 [19:11<00:00,  2.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss =  1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:15<00:00,  6.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss =  1.0\n",
            "epoch  3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 0.3750: 100%|██████████| 3380/3380 [18:52<00:00,  2.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss =  1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:18<00:00,  6.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss =  1.0\n",
            "epoch  4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss: 0.3750: 100%|██████████| 3380/3380 [19:13<00:00,  2.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train loss =  1.0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 845/845 [02:17<00:00,  6.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss =  1.0\n",
            "epoch  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss: 0.8750:  73%|███████▎  | 2456/3380 [13:38<02:28,  6.21it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MyCombinedModel(nn.Module):\n",
        "    def __init__(self, link_state_dim, path_state_dim, num_layers=2):\n",
        "        super(MyCombinedModel, self).__init__()\n",
        "        self.link_embed = LinkEmbedding(link_state_dim)  # Assuming LinkEmbedding is defined\n",
        "        self.flow_embedded = PathEmbedding(path_state_dim)  # Assuming PathEmbedding is defined\n",
        "        self.reader = PathReadout(path_state_dim, link_state_dim)  # Assuming PathReadout is defined\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=link_state_dim, dim_feedforward=64, batch_first=True, nhead=2)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.link_update = nn.GRUCell(\n",
        "          link_state_dim, link_state_dim\n",
        "        )\n",
        "    def forward(self, link_to_path, path_to_link,  link_capacity,  all_flows_used, flow_traffic, link_capacity_orig):\n",
        "\n",
        "        flow_embedding = self.flow_embedded(all_flows_used)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        all_link_capacities_used = []\n",
        "        loads = []\n",
        "\n",
        "        for i in range(len(path_to_link)):\n",
        "\n",
        "            loads.append(torch.sum(torch.index_select(torch.tensor(flow_traffic), 0, torch.tensor(path_to_link[i][:, 0 ]).type(torch.int64)))/  (link_capacity_orig[i] * 1e9))\n",
        "\n",
        "\n",
        "        loads_capacities = torch.cat((torch.tensor(loads).unsqueeze(1), torch.tensor(link_capacity)), dim=1)\n",
        "\n",
        "        capacity_gather = []\n",
        "        for i, values in enumerate(link_to_path):\n",
        "          capacity_gather.append(link_capacity_orig[values])\n",
        "          all_link_capacities_used.append(self.link_embed(torch.tensor(loads_capacities)[values]))\n",
        "\n",
        "        prev_path_state = all_link_capacities_used\n",
        "        print(\"len of link_to_path = \", len(link_to_path), \"path to link \",  len(path_to_link), \"len(all_link_capacities_used) \", len(all_link_capacities_used))\n",
        "        for _ in range(2):\n",
        "          print(_, flow_embedding.unsqueeze(1).shape, torch.cat(all_link_capacities_used, dim=0).shape , torch.nn.utils.rnn.pad_sequence(all_link_capacities_used, batch_first =True).shape)\n",
        "          input_sequence = torch.cat((flow_embedding.unsqueeze(1),torch.nn.utils.rnn.pad_sequence(all_link_capacities_used, batch_first =True)), dim=1)\n",
        "          encoder_out = self.transformer_encoder(input_sequence)\n",
        "          flow_embedding = encoder_out[:, -1, :]\n",
        "\n",
        "          all_link_capacities_used = []\n",
        "          for i, path_link in enumerate(path_to_link):\n",
        "              link_state = self.link_update(torch.index_select(encoder_out[torch.tensor(path_link[:, 0])], 1, torch.tensor(path_link[:, 1]) ).sum(axis=1), )\n",
        "              # print(link_state.shape)\n",
        "              all_link_capacities_used.append(link_state)\n",
        "\n",
        "\n",
        "\n",
        "        output = self.reader(encoder_out[:, 1:, :])\n",
        "\n",
        "        delays = []\n",
        "\n",
        "        for i, out in enumerate(output.squeeze()):\n",
        "            delays.append(torch.sum(out[:len(capacity_gather[i])]/torch.tensor(capacity_gather[i]).T[0]).unsqueeze(0))\n",
        "\n",
        "\n",
        "        return torch.cat(delays)\n",
        "\n",
        "link_state_dim = 64\n",
        "path_state_dim = 64\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "num_layers = 2  # Example value for the number of layers\n",
        "\n",
        "model = MyCombinedModel(link_state_dim,  path_state_dim, num_layers)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "optimizer =  torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, patience=10, mode= 'min')\n",
        "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00001, max_lr=0.1)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = MeanAbsolutePercentageError()\n",
        "\n",
        "def train():\n",
        "  model.train()\n",
        "  fake_batch_size= 32\n",
        "  with tqdm(train_dataset, total=len(train_dataset)) as pbar:\n",
        "    predictions = []\n",
        "    y_all = []\n",
        "    loss = 0\n",
        "    loss = torch.tensor([0.0])\n",
        "\n",
        "    for i,batch in enumerate(pbar):\n",
        "        # print(batch)\n",
        "        # Process the batch as needed\n",
        "        data, labels = batch  # Modify this according to the structure of your data\n",
        "        # print(data.keys())\n",
        "        link_capacity_orig = data['link_capacity'].numpy()\n",
        "        flow_traffic = (data['flow_traffic'].numpy() - normalizers[\"flow_traffic\"][0]) *normalizers[\"flow_traffic\"][1]\n",
        "        flow_packets = (data['flow_packets'].numpy() - normalizers[\"flow_packets\"][0]) *normalizers[\"flow_packets\"][1]\n",
        "        link_capacity = (data['link_capacity'].numpy()  - normalizers[\"link_capacity\"][0]) *normalizers[\"link_capacity\"][1]\n",
        "        flow_packet_size = (data['flow_packet_size'].numpy() - normalizers[\"flow_packet_size\"][0])  * normalizers[\"link_capacity\"][1]\n",
        "        flow_type = data['flow_type'].numpy()\n",
        "        flow_length = data['flow_length'].numpy()\n",
        "        link_to_path = data['link_to_path'].numpy()\n",
        "        flow_ipg_mean = data['flow_ipg_mean'].numpy()\n",
        "        flow_ipg_var = data['flow_ipg_var'].numpy()\n",
        "        path_to_link = data['path_to_link'].numpy()\n",
        "        y_vals = torch.tensor(labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        all_flows_used = torch.tensor(np.concatenate([flow_traffic,flow_packets, flow_type, flow_type, np.expand_dims(flow_length,axis=1)], axis=1,dtype=np.float32 ) )\n",
        "\n",
        "        outputs = model(link_to_path, path_to_link, link_capacity,all_flows_used, flow_traffic, link_capacity_orig)\n",
        "\n",
        "        predictions.extend(outputs.detach().numpy())\n",
        "        loss += criterion(outputs, y_vals ) # Compute the loss.\n",
        "        if i%fake_batch_size == 0 or i== len(train_dataset):\n",
        "          loss = loss/fake_batch_size\n",
        "          loss.backward()  # Derive gradients.\n",
        "          optimizer.step()  # Update parameters based on gradients.\n",
        "          optimizer.zero_grad()  # Clear gradients.\n",
        "          loss = torch.tensor([0.0])\n",
        "\n",
        "        pbar.set_description(f\"Loss: {loss.item()/fake_batch_size:.4f}\")\n",
        "        y_all.extend(labels)\n",
        "    print(\"train loss = \",criterion(torch.tensor(predictions), torch.tensor(y_all )).item())\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    with tqdm(val_dataset, total=len(val_dataset)) as pbar:\n",
        "      predictions = []\n",
        "      y_all = []\n",
        "      for batch in  pbar:\n",
        "          # print(batch)\n",
        "          # Process the batch as needed\n",
        "          data, labels = batch  # Modify this according to the structure of your data\n",
        "          # print(data.keys())\n",
        "          link_capacity_orig = data['link_capacity'].numpy()\n",
        "          flow_traffic = (data['flow_traffic'].numpy() - normalizers[\"flow_traffic\"][0]) *normalizers[\"flow_traffic\"][1]\n",
        "          flow_packets = (data['flow_packets'].numpy() - normalizers[\"flow_packets\"][0]) *normalizers[\"flow_packets\"][1]\n",
        "          link_capacity = (data['link_capacity'].numpy()  - normalizers[\"link_capacity\"][0]) *normalizers[\"link_capacity\"][1]\n",
        "          flow_packet_size = (data['flow_packet_size'].numpy() - normalizers[\"flow_packet_size\"][0])  * normalizers[\"link_capacity\"][1]\n",
        "          flow_type = data['flow_type'].numpy()\n",
        "          flow_length = data['flow_length'].numpy()\n",
        "          link_to_path = data['link_to_path'].numpy()\n",
        "          flow_ipg_mean = data['flow_ipg_mean'].numpy()\n",
        "          flow_ipg_var = data['flow_ipg_var'].numpy()\n",
        "          path_to_link = data['path_to_link'].numpy()\n",
        "          # y_vals = torch.tensor(labels)\n",
        "\n",
        "          # path_gather_traffic = 0\n",
        "          # load = torch.sum(path_gather_traffic, dim=1) / (link_capacity * 1e9)\n",
        "          all_flows_used = torch.tensor(np.concatenate([flow_traffic,flow_packets, flow_type, flow_type, np.expand_dims(flow_length,axis=1)], axis=1,dtype=np.float32 ) )\n",
        "\n",
        "          outputs = model(link_to_path, path_to_link, link_capacity,all_flows_used, flow_traffic, link_capacity_orig)\n",
        "          predictions.extend(outputs.detach().numpy())\n",
        "          y_all.extend(labels)\n",
        "\n",
        "          # scheduler.step(criterion(torch.tensor(predictions), torch.tensor(y_all )))\n",
        "    print(\"val loss = \",criterion(torch.tensor(predictions), torch.tensor(y_all )).item())\n",
        "\n",
        "      # link_gather = torch.gather(torch.tensor(link_capacity), 1,tensor_array, sparse_grad =True, )\n",
        "\n",
        "      # print(link_gather)\n",
        "\n",
        "\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "id": "T4Y4hVYADeL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 50):\n",
        "    print(\"epoch \", epoch)\n",
        "    train()\n",
        "    # train_acc = test(custom_dataset)\n",
        "    # test_acc = test(test_loader)\n",
        "    # print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "    # print(f'Epoch: {epoch:03d}, MAPE: {train_acc:.4f}')\n",
        "\n",
        "\n",
        "model_path = \"model.pth\"\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), model_path)\n"
      ],
      "metadata": {
        "id": "r-gLkKuqVd2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wGKn3ttolb57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFP0qql0gI-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchrec\n"
      ],
      "metadata": {
        "id": "gahfTmM83dJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ragged array\n",
        "ragged_array = [[29, 1, 37, 9, 42, 10, 48],\n",
        "                [28, 29, 1, 37, 8, 45, 13, 49, 27]]\n",
        "\n",
        "# Define the 1D tensor\n",
        "tensor_1d = torch.arange(50)  # Example 1D tensor\n",
        "\n",
        "# Convert the ragged array to a 2D PyTorch tensor\n",
        "padded_array = [torch.LongTensor(sublist) for sublist in ragged_array]\n",
        "max_length = max(len(sublist) for sublist in ragged_array)\n",
        "padded_array = [torch.cat((t, torch.zeros(max_length - len(t), dtype=torch.long))) for t in padded_array]\n",
        "tensor_array = torch.stack(padded_array)\n",
        "\n",
        "# Use the 2D tensor to index the 1D tensor\n",
        "result = tensor_1d[tensor_array]\n",
        "\n",
        "# Filter out the zeros\n",
        "result_ragged = [row[row != 0].tolist() for row in result]\n",
        "\n",
        "# Print the result as a ragged array\n",
        "print(result_ragged)"
      ],
      "metadata": {
        "id": "G7JkG3djysGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link_state_dim = 32\n",
        "path_state_dim = 32 # Example value for link_state_dim\n",
        "\n",
        "# Generate an example input tensor\n",
        "input_tensor = torch.randn(72, 7)  # Example input tensor of shape 72x7\n",
        "print(input_tensor.shape)\n",
        "# Perform the forward pass\n",
        "output = model_embedded(input_tensor)\n",
        "print(output.shape)  # Check the shape of the output"
      ],
      "metadata": {
        "id": "BSg0Z7pWDUPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}